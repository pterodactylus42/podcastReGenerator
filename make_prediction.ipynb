{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYpNHDeFF8xucO9gLHXVYL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pterodactylus42/textReGenerator/blob/main/make_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1fQ7GqS6Bs0"
      },
      "outputs": [],
      "source": [
        "with open(\"etah-murr.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    contents = file.read()\n",
        "\n",
        "contents = contents.split(\"\\n\")\n",
        "contents = [line.strip() for line in contents if \"#\" not in line]\n",
        "\n",
        "contents = \"\\n\".join(contents)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"word_to_int.etah.pickle\", \"rb\") as file:\n",
        "    word_to_int = pickle.load(file)\n",
        "\n",
        "with open(\"int_to_word.etah.pickle\", \"rb\") as file:\n",
        "    int_to_word = pickle.load(file)"
      ],
      "metadata": {
        "id": "nlMYW9nw6Go2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "# nltk.download('punkt_tab')\n",
        "tokens = word_tokenize(contents)\n",
        "\n",
        "tokens_transformed = [word_to_int[word] for word in tokens if word in word_to_int]"
      ],
      "metadata": {
        "id": "83zOe9276Kxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model(\"etah.keras\")"
      ],
      "metadata": {
        "id": "s93p5tWg6Oi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = tokens_transformed[100:140]\n",
        "\n",
        "print(\" \".join([int_to_word[token] for token in sentence]).replace(\"\\\\n\", \"\\n\"))"
      ],
      "metadata": {
        "id": "3dKgMqjO6RpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict() :\n",
        "    sentence = np.array(tokens_transformed[100:140])\n",
        "    predicted_text = np.array([]);\n",
        "    for i in range(0, 300):\n",
        "        prediction = model.predict(sentence.reshape(1, 40))\n",
        "\n",
        "        # word = np.argmax(prediction[0])\n",
        "        word = np.random.choice(len(int_to_word), p=prediction[0])\n",
        "        sentence = np.append(sentence[1:], [word])\n",
        "        predicted_text = np.append(predicted_text, int_to_word[word])\n",
        "\n",
        "    result = \" \".join(predicted_text).replace(\"\\\\n\", \"\\n\")\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "ukyVvnoP6Ux0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_text = predict()\n",
        "print(predicted_text)"
      ],
      "metadata": {
        "id": "xhIxq-EA6YVq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}